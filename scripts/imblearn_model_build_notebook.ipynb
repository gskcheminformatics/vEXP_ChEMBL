{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sweet-starter",
   "metadata": {},
   "source": [
    "# Model Building Setup for Safety Models using RdKit descriptors and ChEMBL31 data only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "geological-niagara",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ceaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "model_dir = \"ADRA2A_PIC50\"\n",
    "data_file_name = \"./ADRA2A_PIC50_train.tsv\"\n",
    "# output\n",
    "scalar_file_name = \"./scalar_ADRA2A_PIC50.pkl\"\n",
    "ecc_model_file = \"./ADRA2A_PIC50_svm.pkl\"\n",
    "brf_model_file = \"./ADRA2A_PIC50_xgb.pkl\"\n",
    "rusb_model_file = \"./ADRA2A_PIC50_rusb.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italian-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, balanced_accuracy_score, matthews_corrcoef, cohen_kappa_score \n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "after-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier,BalancedRandomForestClassifier,RUSBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dangerous-madrid",
   "metadata": {},
   "source": [
    "# Get Mols, Data and generate descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dramatic-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file_name, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gothic-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_str = df.class_label.tolist() \n",
    "y_int = pd.get_dummies(y_str)\n",
    "y_new = y_int[\"POSITIVE\"] \n",
    "df['class_label_binary'] = y_new \n",
    "y = df.class_label_binary.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [Chem.MolFromSmiles(smi) for smi in df.parentised_smiles]\n",
    "# generate binary Morgan fingerprint with radius 2\n",
    "fp = [AllChem.GetMorganFingerprintAsBitVect(m, 2) for m in mols]\n",
    "# generate binary Morgan fingerprint with radius 2 with physchem as numpy array\n",
    "x = rdkit_fpconvert_numpy(fp)\n",
    "x = np.concatenate((x, rdkit_get_physchem_descr(mols)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-blogger",
   "metadata": {},
   "source": [
    "## Scale using scalar from last run and calculate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "major-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 20% of compounds as test set but with stratified selection\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.20, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalar\n",
    "scale = joblib.load(scalar_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "seventh-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = scale.transform(x_tr)\n",
    "x_ts = scale.transform(x_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac5546",
   "metadata": {},
   "source": [
    "# IMBLearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9d7d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ....................................n_estimators=10; total time=   1.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   1.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   1.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   1.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   1.7s\n",
      "[CV] END ....................................n_estimators=30; total time=   5.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   5.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   5.1s\n",
      "[CV] END ....................................n_estimators=30; total time=   5.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   5.2s\n",
      "[CV] END ....................................n_estimators=50; total time=   8.6s\n",
      "[CV] END ....................................n_estimators=50; total time=   8.6s\n",
      "[CV] END ....................................n_estimators=50; total time=   8.6s\n",
      "[CV] END ....................................n_estimators=50; total time=   8.7s\n",
      "[CV] END ....................................n_estimators=50; total time=   8.7s\n",
      "[CV] END ...................................n_estimators=100; total time=  20.9s\n",
      "[CV] END ...................................n_estimators=100; total time=  18.7s\n",
      "[CV] END ...................................n_estimators=100; total time=  17.2s\n",
      "[CV] END ...................................n_estimators=100; total time=  17.2s\n",
      "[CV] END ...................................n_estimators=100; total time=  17.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./ADRA2A_PIC50_eec.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create grid search dictionary\n",
    "eec_param_grid = {\"n_estimators\": [i for i in [10, 30, 50, 100]]}\n",
    "# model build\n",
    "eec = GridSearchCV(EasyEnsembleClassifier(n_jobs=-1),\n",
    "                  verbose=2,\n",
    "                  scoring='balanced_accuracy',\n",
    "                  param_grid=eec_param_grid, cv=5,\n",
    "                  n_jobs=-1)\n",
    "eec.fit(x_tr, y_tr)\n",
    "# save model\n",
    "joblib.dump(eec, ecc_model_file, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "similar-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ....................................n_estimators=10; total time=   0.0s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.0s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.0s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.0s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.0s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.2s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.2s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.2s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.2s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./ADRA2A_PIC50_brf.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create grid search dictionary\n",
    "brf_param_grid = {\"n_estimators\": [i for i in [10, 30, 50, 100]]}\n",
    "# model build\n",
    "brf = GridSearchCV(BalancedRandomForestClassifier(n_jobs=-1, replacement=True, sampling_strategy='all'),\n",
    "                  verbose=2,\n",
    "                  scoring='balanced_accuracy',\n",
    "                  param_grid=eec_param_grid, cv=5,\n",
    "                  n_jobs=-1)\n",
    "brf.fit(x_tr, y_tr)\n",
    "# save model\n",
    "joblib.dump(brf, brf_model_file, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "postal-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ....................................n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   0.2s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.3s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.3s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.3s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.3s\n",
      "[CV] END ....................................n_estimators=50; total time=   0.3s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.6s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.5s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.6s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.6s\n",
      "[CV] END ...................................n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./ADRA2A_PIC50_rusb.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create grid search dictionary\n",
    "rusb_param_grid = {\"n_estimators\": [i for i in [10, 30, 50, 100]]}\n",
    "# model build\n",
    "rusb = GridSearchCV(RUSBoostClassifier(),\n",
    "                  verbose=2,\n",
    "                  scoring='balanced_accuracy',\n",
    "                  param_grid=eec_param_grid, cv=5,\n",
    "                  n_jobs=-1)\n",
    "rusb.fit(x_tr, y_tr)\n",
    "# save model\n",
    "joblib.dump(eec, rusb_model_file, compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fe83a",
   "metadata": {},
   "source": [
    "## Test Set Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expressed-monday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEC Train:\n",
      "Precision =  1.0\n",
      "ROC-AUC =  0.9060457516339869\n",
      "Balanced Accuracy Score =  0.9060457516339869\n",
      "MCC =  0.6225665639589993\n",
      "Kappa =  0.5586511441188278\n"
     ]
    }
   ],
   "source": [
    "# predict for the test set compounds\n",
    "pred_eec_tr = eec.predict(x_tr)\n",
    "# calc statistics\n",
    "print(\"EEC Train:\")\n",
    "print(\"Precision = \", precision_score(y_tr, pred_eec_tr))\n",
    "print(\"ROC-AUC = \", roc_auc_score(y_tr, pred_eec_tr))\n",
    "print(\"Balanced Accuracy Score = \", balanced_accuracy_score(y_tr, pred_eec_tr))\n",
    "print(\"MCC = \", matthews_corrcoef(y_tr, pred_eec_tr))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_tr, pred_eec_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e5f09ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEC Test:\n",
      "Precision =  0.9916666666666667\n",
      "ROC-AUC =  0.8671328671328672\n",
      "Balanced Accuracy Score =  0.8671328671328671\n",
      "MCC =  0.547562941427901\n",
      "Kappa =  0.47572815533980584\n"
     ]
    }
   ],
   "source": [
    "# predict for the test set compounds\n",
    "pred_eec_ts = eec.predict(x_ts)\n",
    "# calc statistics\n",
    "print(\"EEC Test:\")\n",
    "print(\"Precision = \", precision_score(y_ts, pred_eec_ts))\n",
    "print(\"ROC-AUC = \", roc_auc_score(y_ts, pred_eec_ts))\n",
    "print(\"Balanced Accuracy Score = \", balanced_accuracy_score(y_ts, pred_eec_ts))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_eec_ts))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_eec_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "maritime-indie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRF Train:\n",
      "Precision =  1.0\n",
      "ROC-AUC =  0.928921568627451\n",
      "Balanced Accuracy Score =  0.928921568627451\n",
      "MCC =  0.6849328183743822\n",
      "Kappa =  0.6386528335331838\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "# predict for the test set compounds\n",
    "pred_brf_tr = brf.predict(x_tr)\n",
    "# calc statistics\n",
    "print(\"BRF Train:\")\n",
    "print(\"Precision = \", precision_score(y_tr, pred_brf_tr))\n",
    "print(\"ROC-AUC = \", roc_auc_score(y_tr, pred_brf_tr))\n",
    "print(\"Balanced Accuracy Score = \", balanced_accuracy_score(y_tr, pred_brf_tr))\n",
    "print(\"MCC = \", matthews_corrcoef(y_tr, pred_brf_tr))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_tr, pred_brf_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "latin-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRF Train:\n",
      "Precision =  0.9761904761904762\n",
      "ROC-AUC =  0.8416583416583416\n",
      "Balanced Accuracy Score =  0.8416583416583416\n",
      "MCC =  0.5241877966925762\n",
      "Kappa =  0.4720496894409938\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "# predict for the test set compounds\n",
    "pred_brf_ts = brf.predict(x_ts)\n",
    "# calc statistics\n",
    "print(\"BRF Train:\")\n",
    "print(\"Precision = \", precision_score(y_ts, pred_brf_ts))\n",
    "print(\"ROC-AUC = \", roc_auc_score(y_ts, pred_brf_ts))\n",
    "print(\"Balanced Accuracy Score = \", balanced_accuracy_score(y_ts, pred_brf_ts))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_brf_ts))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_brf_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exact-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSB Train:\n",
      "Precision =  0.9320388349514563\n",
      "ROC-AUC =  0.7254901960784313\n",
      "Balanced Accuracy Score =  0.7254901960784313\n",
      "MCC =  0.35444489141573904\n",
      "Kappa =  0.32616953387469827\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "# predict for the test set compounds\n",
    "pred_rusb_tr = rusb.predict(x_tr)\n",
    "# calc statistics\n",
    "print(\"RUSB Train:\")\n",
    "print(\"Precision = \", precision_score(y_tr, pred_rusb_tr))\n",
    "print(\"ROC-AUC = \", roc_auc_score(y_tr, pred_rusb_tr))\n",
    "print(\"Balanced Accuracy Score = \", balanced_accuracy_score(y_tr, pred_rusb_tr))\n",
    "print(\"MCC = \", matthews_corrcoef(y_tr, pred_rusb_tr))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_tr, pred_rusb_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "formal-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSB Train:\n",
      "Precision =  0.9083969465648855\n",
      "ROC-AUC =  0.6555944055944056\n",
      "Balanced Accuracy Score =  0.6555944055944056\n",
      "MCC =  0.24577478229336402\n",
      "Kappa =  0.22753834915997084\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "# predict for the test set compounds\n",
    "pred_rusb_ts = rusb.predict(x_ts)\n",
    "# calc statistics\n",
    "print(\"RUSB Train:\")\n",
    "print(\"Precision = \", precision_score(y_ts, pred_rusb_ts))\n",
    "print(\"ROC-AUC = \", roc_auc_score(y_ts, pred_rusb_ts))\n",
    "print(\"Balanced Accuracy Score = \", balanced_accuracy_score(y_ts, pred_rusb_ts))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_rusb_ts))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_rusb_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-ocean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-westminster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-customer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-bradley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_qsar_imb)",
   "language": "python",
   "name": "conda_qsar_imb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2bb8ba4dbbd1922056eae260ebdf0a3570f5d6445cea652291a72b5d24d4404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
